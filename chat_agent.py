# # âœ… LangGraph ê¸°ë°˜ìœ¼ë¡œ ë¦¬íŒ©í† ë§ëœ agent.py

# # ğŸŒ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
# import os
# from typing import TypedDict, Annotated
# from dotenv import load_dotenv

# # ğŸ¤– LangChain ê´€ë ¨
# from langchain_openai import ChatOpenAI
# from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage
# from langchain_core.runnables import RunnableConfig

# # ğŸ§  LangGraph ê´€ë ¨
# from langgraph.graph import StateGraph, START, END
# from langgraph.graph.message import add_messages
# from langgraph.prebuilt import ToolNode, tools_condition
# from langgraph.checkpoint.memory import MemorySaver

# # ğŸ› ï¸ ì‚¬ìš©ì ì •ì˜ ë„êµ¬
# from llm_tools.retriever import RAG_tool
# from llm_tools.get_weather import get_weather_by_location_and_date
# from llm_tools.google_places import get_places_by_keyword_and_location
# from llm_tools.naver_search import NaverSearchTool
# from llm_tools.chat_history_manager import ChatHistoryManager

# # ğŸ§¾ í”„ë¡¬í”„íŠ¸
# from system_prompt import get_system_prompt

# # âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# load_dotenv()

# # âœ… ìƒíƒœ ì €ì¥ì†Œ
# memory = MemorySaver()
# chat_store = ChatHistoryManager()


# # âœ… ìƒíƒœ ì •ì˜
# class State(TypedDict):
#     session_id: str
#     messages: Annotated[list, add_messages]


# # âœ… Config ìƒì„± í•¨ìˆ˜
# def generate_config(session_id: str) -> RunnableConfig:
#     return RunnableConfig(
#         recursion_limit=10,
#         configurable={"thread_id": session_id},
#         tags=["my-tag"]
#     )


# # âœ… System Prompt ì‚½ì… ë…¸ë“œ
# def prompt_node(state: State) -> State:
#     system_msg = SystemMessage(content=get_system_prompt())
#     if not any(msg.type == "system" for msg in state["messages"]):
#         state["messages"] = [system_msg] + state["messages"]
#     return state


# # âœ… ChatBot ë…¸ë“œ (LLM í˜¸ì¶œ + DB ì €ì¥)
# def build_chatbot_node(tools):
#     llm = ChatOpenAI(model_name='gpt-4.1')
#     llm_with_tools = llm.bind_tools(tools)

#     # LLMì— ì „ë‹¬í•  ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
#     MAX_HISTORY_MESSAGES = 10 # í•„ìš”ì— ë”°ë¼ ì´ ê°’ì„ ì¡°ì •í•˜ì„¸ìš”.

#     def chatbot(state: State) -> State:
#         # ìµœê·¼ ë©”ì‹œì§€ë§Œ LLMì— ì „ë‹¬
#         messages_to_send = state["messages"][-MAX_HISTORY_MESSAGES:]
#         response = llm_with_tools.invoke(messages_to_send)
#         # âœ… DBì— ì €ì¥: í˜„ì¬ í„´ì˜ ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ë´‡ ì‘ë‹µë§Œ ì €ì¥
#         history = chat_store.get_session_history(state["session_id"])

#         # í˜„ì¬ í„´ì˜ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
#         # state["messages"]ëŠ” ëˆ„ì ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ, ë§ˆì§€ë§‰ HumanMessageê°€ í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ì…ë‹ˆë‹¤.
#         user_message_for_this_turn = None
#         for msg in reversed(state["messages"]):
#             if isinstance(msg, HumanMessage):
#                 user_message_for_this_turn = msg
#                 break

#         if user_message_for_this_turn:
#             history.add_message(user_message_for_this_turn)
#         history.add_message(response) # ë´‡ ì‘ë‹µ ì €ì¥

#         return {"session_id": state["session_id"], "messages": [response]} # ë‹¤ìŒ ìƒíƒœì—ëŠ” í˜„ì¬ ì‘ë‹µë§Œ í¬í•¨

#     return chatbot


# # âœ… ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì •ì˜ í•¨ìˆ˜
# def agent():
#     # ë„êµ¬ ì •ì˜
#     naver = NaverSearchTool()
#     tools = [RAG_tool, get_weather_by_location_and_date, naver]

#     # LangGraph ì •ì˜
#     graph = StateGraph(State)

#     # ë…¸ë“œ ë“±ë¡
#     graph.add_node("prompt", prompt_node)
#     graph.add_node("chatbot", build_chatbot_node(tools))
#     graph.add_node("tools", ToolNode(tools=tools))

#     # ë…¸ë“œ ì—°ê²°
#     graph.add_edge(START, "prompt")
#     graph.add_edge("prompt", "chatbot")
#     graph.add_conditional_edges("chatbot", tools_condition)
#     graph.add_edge("tools", "chatbot")
#     graph.add_edge("chatbot", END)

#     return graph.compile(checkpointer=memory)
